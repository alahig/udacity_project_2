{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL Pipeline Preparation\n",
    "### 1. Import libraries and load datasets.\n",
    "#- Import Python libraries\n",
    "#- Load `messages.csv` into a dataframe and inspect the first few lines.\n",
    "#- Load `categories.csv` into a dataframe and inspect the first few lines.\n",
    "\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# load messages dataset\n",
    "messages = pd.read_csv('messages.csv')\n",
    "\n",
    "\n",
    "# load categories dataset\n",
    "categories = pd.read_csv('categories.csv')\n",
    "\n",
    "\n",
    "### 2. Merge datasets.\n",
    "#- Merge the messages and categories datasets using the common id\n",
    "#- Assign this combined dataset to `df`, which will be cleaned in the following steps\n",
    "\n",
    "# merge datasets\n",
    "df = messages.merge(categories, how='left', on='id')\n",
    "\n",
    "\n",
    "### 3. Split `categories` into separate category columns.\n",
    "#- Split the values in the `categories` column on the `;` character so that each value becomes a separate column. You'll find [this method](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.str.split.html) very helpful! Make sure to set `expand=True`.\n",
    "#- Use the first row of categories dataframe to create column names for the categories data.\n",
    "#- Rename columns of `categories` with new column names.\n",
    "\n",
    "categories = categories.set_index('id').squeeze()\n",
    "\n",
    "def convert_feature_list(li):\n",
    "    ''' Converts a string in the format \n",
    "        'related-1;request-0;offer-0;\n",
    "        to a dict where the category names are the keys \n",
    "        and the values are the integers.\n",
    "        i.e. {'related': 1, 'request': 0, 'offer': 0}\n",
    "        \n",
    "    '''\n",
    "    elements = li.split(';')\n",
    "    return {k.split('-')[0]: int(k.split('-')[-1]) for k in elements}\n",
    "\n",
    "categories = pd.DataFrame({i: convert_feature_list(v) for i, v in categories.items()}).T\n",
    "\n",
    "\n",
    "# There are a few entries where the related value is 2. This should be considered a dataerror\n",
    "# i.e. \n",
    "# categories.loc[4145]\n",
    "# 'related-2;request-0;offer-0;aid_related-0;medical_help-0;medical_products-0;search_and_rescue-0;security-0;military-0;child_alone-0;water-0;food-0;shelter-0;clothing-0;money-0;missing_people-0;refugees-0;death-0;other_aid-0;infrastructure_related-0;transport-0;buildings-0;electricity-0;tools-0;hospitals-0;shops-0;aid_centers-0;other_infrastructure-0;weather_related-0;floods-0;storm-0;fire-0;earthquake-0;cold-0;other_weather-0;direct_report-0'\n",
    "categories = categories.clip(upper=1)\n",
    "\n",
    "\n",
    "df = messages.merge(categories, how='left', left_on='id', right_index=True)\n",
    "\n",
    "### 6. Remove duplicates.\n",
    "\n",
    "# check number of duplicates\n",
    "df.duplicated().sum()\n",
    "\n",
    "# drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# check number of duplicates\n",
    "assert not(df.duplicated().any())\n",
    "\n",
    "### 7. Save the clean dataset into an sqlite database.\n",
    "engine = create_engine('sqlite:///message_data.db')\n",
    "df.to_sql('InsertTableName', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Use this notebook to complete `etl_pipeline.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database based on new datasets specified by the user. Alternatively, you can complete `etl_pipeline.py` in the classroom on the `Project Workspace IDE` coming later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = pd.read_csv('categories.csv')\n",
    "\n",
    "\n",
    "### 2. Merge datasets.\n",
    "#- Merge the messages and categories datasets using the common id\n",
    "#- Assign this combined dataset to `df`, which will be cleaned in the following steps\n",
    "\n",
    "# merge datasets\n",
    "df = messages.merge(categories, how='left', on='id')\n",
    "\n",
    "\n",
    "### 3. Split `categories` into separate category columns.\n",
    "#- Split the values in the `categories` column on the `;` character so that each value becomes a separate column. You'll find [this method](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.str.split.html) very helpful! Make sure to set `expand=True`.\n",
    "#- Use the first row of categories dataframe to create column names for the categories data.\n",
    "#- Rename columns of `categories` with new column names.\n",
    "\n",
    "categories = categories.set_index('id').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "2        related-1;request-0;offer-0;aid_related-0;medi...\n",
       "7        related-1;request-0;offer-0;aid_related-1;medi...\n",
       "8        related-1;request-0;offer-0;aid_related-0;medi...\n",
       "9        related-1;request-1;offer-0;aid_related-1;medi...\n",
       "12       related-1;request-0;offer-0;aid_related-0;medi...\n",
       "14       related-0;request-0;offer-0;aid_related-0;medi...\n",
       "15       related-1;request-0;offer-0;aid_related-0;medi...\n",
       "16       related-1;request-1;offer-0;aid_related-1;medi...\n",
       "17       related-0;request-0;offer-0;aid_related-0;medi...\n",
       "18       related-1;request-1;offer-0;aid_related-1;medi...\n",
       "20       related-1;request-1;offer-0;aid_related-1;medi...\n",
       "21       related-0;request-0;offer-0;aid_related-0;medi...\n",
       "22       related-1;request-1;offer-0;aid_related-1;medi...\n",
       "24       related-1;request-1;offer-0;aid_related-1;medi...\n",
       "25       related-1;request-0;offer-0;aid_related-0;medi...\n",
       "26       related-1;request-1;offer-0;aid_related-1;medi...\n",
       "27       related-1;request-1;offer-0;aid_related-1;medi...\n",
       "28       related-0;request-0;offer-0;aid_related-0;medi...\n",
       "30       related-0;request-0;offer-0;aid_related-0;medi...\n",
       "31       related-1;request-0;offer-0;aid_related-0;medi...\n",
       "32       related-1;request-0;offer-0;aid_related-0;medi...\n",
       "33       related-1;request-1;offer-0;aid_related-1;medi...\n",
       "34       related-1;request-1;offer-0;aid_related-1;medi...\n",
       "35       related-1;request-1;offer-0;aid_related-1;medi...\n",
       "36       related-1;request-0;offer-0;aid_related-0;medi...\n",
       "37       related-0;request-0;offer-0;aid_related-0;medi...\n",
       "38       related-1;request-1;offer-0;aid_related-1;medi...\n",
       "39       related-1;request-1;offer-0;aid_related-1;medi...\n",
       "41       related-1;request-1;offer-0;aid_related-1;medi...\n",
       "42       related-1;request-1;offer-0;aid_related-1;medi...\n",
       "                               ...                        \n",
       "30233    related-1;request-0;offer-0;aid_related-1;medi...\n",
       "30234    related-1;request-0;offer-0;aid_related-1;medi...\n",
       "30235    related-1;request-0;offer-0;aid_related-1;medi...\n",
       "30236    related-0;request-0;offer-0;aid_related-0;medi...\n",
       "30237    related-0;request-0;offer-0;aid_related-0;medi...\n",
       "30238    related-1;request-0;offer-0;aid_related-1;medi...\n",
       "30239    related-1;request-0;offer-0;aid_related-0;medi...\n",
       "30240    related-1;request-0;offer-0;aid_related-1;medi...\n",
       "30241    related-1;request-0;offer-0;aid_related-0;medi...\n",
       "30242    related-0;request-0;offer-0;aid_related-0;medi...\n",
       "30243    related-1;request-0;offer-0;aid_related-0;medi...\n",
       "30245    related-1;request-0;offer-0;aid_related-1;medi...\n",
       "30246    related-1;request-0;offer-0;aid_related-1;medi...\n",
       "30247    related-1;request-0;offer-0;aid_related-1;medi...\n",
       "30248    related-0;request-0;offer-0;aid_related-0;medi...\n",
       "30249    related-1;request-0;offer-0;aid_related-0;medi...\n",
       "30250    related-1;request-0;offer-0;aid_related-0;medi...\n",
       "30251    related-1;request-0;offer-0;aid_related-1;medi...\n",
       "30253    related-0;request-0;offer-0;aid_related-0;medi...\n",
       "30254    related-1;request-0;offer-0;aid_related-1;medi...\n",
       "30255    related-1;request-0;offer-0;aid_related-1;medi...\n",
       "30256    related-1;request-1;offer-0;aid_related-0;medi...\n",
       "30257    related-1;request-0;offer-0;aid_related-0;medi...\n",
       "30258    related-0;request-0;offer-0;aid_related-0;medi...\n",
       "30259    related-1;request-0;offer-0;aid_related-0;medi...\n",
       "30261    related-0;request-0;offer-0;aid_related-0;medi...\n",
       "30262    related-0;request-0;offer-0;aid_related-0;medi...\n",
       "30263    related-1;request-0;offer-0;aid_related-0;medi...\n",
       "30264    related-1;request-0;offer-0;aid_related-1;medi...\n",
       "30265    related-1;request-0;offer-0;aid_related-0;medi...\n",
       "Name: categories, Length: 26248, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'related-2;request-0;offer-0;aid_related-0;medical_help-0;medical_products-0;search_and_rescue-0;security-0;military-0;child_alone-0;water-0;food-0;shelter-0;clothing-0;money-0;missing_people-0;refugees-0;death-0;other_aid-0;infrastructure_related-0;transport-0;buildings-0;electricity-0;tools-0;hospitals-0;shops-0;aid_centers-0;other_infrastructure-0;weather_related-0;floods-0;storm-0;fire-0;earthquake-0;cold-0;other_weather-0;direct_report-0'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories.loc[4145]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
